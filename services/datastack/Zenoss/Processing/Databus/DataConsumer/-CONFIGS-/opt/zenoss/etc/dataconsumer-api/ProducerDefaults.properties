# Properties applicable to the Databus and its associated components

#
# Schema Registry
#
schema.registry.url=http://172.31.43.108:8081,http://172.31.43.216:8081,http://172.31.45.107:8081
registry.max.schemas.per.subject=1000
key.serializer=io.confluent.kafka.serializers.KafkaAvroSerializer
value.serializer=io.confluent.kafka.serializers.KafkaAvroSerializer
bootstrap.servers=172.31.43.108:9092,172.31.43.216:9092,172.31.45.107:9092

#topic.name= <NAME_OF_TOPIC>

# The program has a sane default for the client id, but can be overridden here
#client.id = 

# Controls when a producer send returns. 
# 0 --> Return immediately, without waiting for broker to ack
# 1 --> Wait for lead broker to ack receipt of message. DEFAULT for Databus usage
# 2 --> wait for atleast 2 replica brokers to ack
# all --> All replica brokers must ack
request.required.acks = 1 #legacy
acks = 1

# Wait time in millisecs for an ack before returning an error. 
#request.timeout.ms = 10000

# send mode. values: sync (default), async
producer.type = sync

#  override with specific partitioner class
#partitioner.class = kafka.producer.DefaultPartitioner
# compression values: none, gzip, snappy
#compression.type = none

# >0 enables producer level retries for failure. Usually handled at higher client level
#retries = 0

# controls the max size sent to partition
#batch.size = 16384

# time to wait to fill up batch.size worth of records to send
linger.ms = 5

#max.request.size = 1048576
#receive.buffer.bytes = 32768
#send.buffer.bytes = 131072

# set to false to immediately throw a BufferExhaustedException
#block.on.buffer.full = true

#metadata.fetch.timeout.ms = 60000
#reconnect.backoff.ms = 50
#retry.backoff.ms = 100
#max.block.ms = 60000

#ProducerPool properties
#  mode controls whether the pool shares the underlying kafka publisher. Values: shared (default), discrete
producer.pool.mode = shared

#producer.pool.block.when.exhausted = true
#max producers per key
#producer.pool.max.total.perKey = 8

#max over all. Overrides perKey. default = -1 (unlimited)
#producer.pool.max.total = -1
#producer.pool.max.idle.perKey = 8
#producer.pool.min.idle.perKey = 0


